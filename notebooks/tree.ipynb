{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from typing import List, Tuple\n",
    "from logging import getLogger, StreamHandler, INFO\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import seaborn as sns\n",
    "import pygwalker as pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = getLogger(__name__)\n",
    "logger.setLevel(INFO)\n",
    "logger.addHandler(StreamHandler())\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_INPUT_FILE = 'example_data.csv'\n",
    "MIN_COMP_RATIO = 0.05\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.environ.get('INPUT_DATA_DIR')\n",
    "OUTPUT_DATA_DIR = os.environ.get('OUTPUT_DATA_DIR')\n",
    "assert INPUT_DATA_DIR is not None\n",
    "assert OUTPUT_DATA_DIR is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name: str=DEFAULT_INPUT_FILE):\n",
    "    f = os.path.join(INPUT_DATA_DIR, file_name)\n",
    "    return pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_nice(numbers: List[float], data_min: float, data_max: float, n_digits: int=1) -> List[float]:\n",
    "    rounded_numbers = list()\n",
    "    for number in numbers:\n",
    "        exponent = math.floor(math.log10(number))\n",
    "        base = 10 ** exponent\n",
    "        factor = number / base\n",
    "\n",
    "        # Determine if it is close to 1, 2, or 5\n",
    "        if factor < 1.5:\n",
    "            rounded_numbers.append(1 * base)\n",
    "        elif factor < 3.5:\n",
    "            rounded_numbers.append(2 * base)\n",
    "        else:\n",
    "            rounded_numbers.append(5 * base)\n",
    "\n",
    "    rounded_numbers = sorted(list(set(rounded_numbers)))\n",
    "\n",
    "    # if min value in original numbers is less than min of rounded numbers, then add a smaller number\n",
    "    if data_min < min(rounded_numbers):\n",
    "        rounded_numbers.insert(0, data_min)\n",
    "    # if max value in original numbers is greater than max of rounded numbers, then add a larger number\n",
    "    if data_max > max(rounded_numbers):\n",
    "        rounded_numbers.append(data_max)\n",
    "\n",
    "    return rounded_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_thresholds(df: pd.DataFrame, col: str, nice_round: bool) -> List[float]:\n",
    "    n = df[col].count()\n",
    "    k = int(1 + math.log2(n))  # Sturges' formula\n",
    "\n",
    "    unique_values = df[col].unique().tolist()\n",
    "    if len(unique_values) <= 1:\n",
    "        return list()\n",
    "\n",
    "    if len(unique_values) <= k:\n",
    "        cut_points = sorted(unique_values)\n",
    "    else:\n",
    "        bins = pd.qcut(df[col], q=k, duplicates='drop')\n",
    "        cut_points = [df[col].min()] + [bins.cat.categories[i].right for i in range(len(bins.cat.categories))]\n",
    "\n",
    "    if nice_round:\n",
    "        # Round to the nearest 1, 2, or 5 multiples of one significant digit\n",
    "        cut_points = round_nice(cut_points, data_min=min(df[col]), data_max=max(df[col]))\n",
    "\n",
    "    return cut_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_records(df: pd.DataFrame, col: str, nice_round: bool) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge adjacent records with adjacent values in col and the same predicted result\n",
    "    \"\"\"\n",
    "    cut_points = calculate_thresholds(df, col, nice_round=nice_round)\n",
    "\n",
    "    # Create a new column with the bin number\n",
    "    df[f'bin_{col}'] = pd.cut(df[col], bins=cut_points, labels=None, include_lowest=True)\n",
    "    df[f'bin_{col}_str'] = df[f'bin_{col}'].apply(lambda x: f'{x.left} < {col} <= {x.right}')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df: pd.DataFrame, target_col: str, pred_col: str, feature_cols: List[str]) -> pd.DataFrame:\n",
    "    df.rename(columns={\n",
    "        feature_cols[0]: 'feature_1_value',\n",
    "        feature_cols[1]: 'feature_2_value',\n",
    "        'bin_{}_str'.format(feature_cols[0]): 'feature_1_range',\n",
    "        'bin_{}_str'.format(feature_cols[1]): 'feature_2_range',\n",
    "    }, inplace=True)\n",
    "    df['feature_1'] = feature_cols[0]\n",
    "    df['feature_2'] = feature_cols[1]\n",
    "    df = df[['feature_1', 'feature_2', 'feature_1_range', 'feature_2_range', 'feature_1_value', 'feature_2_value', target_col, pred_col, 'leaf_node']]\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put index to Details field\n",
    "# pyg.walk(df.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = df.columns[0]\n",
    "pred_col = f'{target_col}_pred'\n",
    "feature_cols = df.drop(target_col, axis=1).columns.tolist()\n",
    "min_samples = math.ceil(len(df) * MIN_COMP_RATIO)\n",
    "\n",
    "# featureから2つ選んでリストにする\n",
    "feature_col_pairs = [[feature_cols[i], feature_cols[j]] for i in range(len(feature_cols)) for j in range(i+1, len(feature_cols))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master = pd.DataFrame()\n",
    "for feature_col_pair in feature_col_pairs[:1]:\n",
    "    X = df[feature_col_pair]\n",
    "    y = df[target_col]\n",
    "\n",
    "    model = DecisionTreeClassifier(min_samples_leaf=min_samples, min_impurity_decrease=0, random_state=RANDOM_STATE)\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict_proba(X)\n",
    "    leaf_nodes = model.apply(X)\n",
    "\n",
    "    df_pred = df[feature_col_pair].copy()\n",
    "    df_pred[target_col] = y\n",
    "    df_pred[pred_col] = y_pred[:, 1]\n",
    "    df_pred['leaf_node'] = leaf_nodes\n",
    "\n",
    "    plot_tree(model, feature_names=feature_col_pair, class_names=[f'not {target_col}', target_col], filled=True)\n",
    "\n",
    "    # assessment\n",
    "    accuracy = model.score(X, y)\n",
    "    logger.info(f'{feature_col_pair}, {accuracy}')\n",
    "    df_pred.plot.scatter(x=feature_col_pair[0], y=feature_col_pair[1], c=pred_col, colormap='viridis')\n",
    "\n",
    "    for feature_col in feature_col_pair:\n",
    "        df_pred = bin_records(df_pred, feature_col, nice_round=False)\n",
    "\n",
    "    df_pred = rename_columns(df_pred, target_col=target_col, pred_col=pred_col, feature_cols=feature_col_pair)\n",
    "    df_pred.sort_values(by=['feature_1_value', 'feature_2_value'], inplace=True)\n",
    "\n",
    "    display(df_pred)\n",
    "    df_master = pd.concat([df_master, df_pred], axis=0).reset_index(drop=True)\n",
    "\n",
    "df_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate\n",
    "df_agg = df_master.groupby(['feature_1_range', 'feature_2_range']).agg({target_col: ['count', 'mean'], pred_col: 'mean'}).reset_index()\n",
    "df_agg.columns = ['feature_1_range', 'feature_2_range', 'target count', 'target pred mean', 'pred mean']\n",
    "df_agg = df_agg[df_agg['target count'] >= min_samples]\n",
    "df_agg.sort_values(by=['target pred mean'], ascending=False, inplace=True)\n",
    "df_agg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
